{
 "metadata": {
  "name": "Python_classification.ipynb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Document-level text analysis\n",
      "\n",
      "Document-level analysis is when you are interested in the whole text article, not tokens (sentences or words).  The most basic example is labeling documents against some classification scheme, hence **text classification**.  When you don't know your scheme ahead of time or you're interested in exploring a large set of data, you can try **topic modeling**.\n",
      "\n",
      "We're going to go over a couple of examples of document-level text analysis using some very most common classifiers models.  We're going to go over the code to train your own model and discuss the results we see.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Supervised learning: Text classification in Python\n",
      "\n",
      "We're going to go over examples of how to use the excellent [Scikits-Learn](http://scikit-learn.org/stable/) library to train some text classifiers.  \n",
      "\n",
      "The dataset used are the titles and topic codes from the `NYTimes` dataset that comes with the RTextTools library in `R`.  It consists of titles from NYTimes front page news and associated codes according to [Amber Boydstun's classification scheme](http://www.policyagendas.org/sites/policyagendas.org/files/Boydstun_NYT_FrontPage_Codebook_0.pdf).\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn import metrics\n",
      "from operator import itemgetter\n",
      "from sklearn.metrics import classification_report\n",
      "import csv\n",
      "import os\n",
      "\n",
      "os.chdir('/Users/rweiss/Dropbox/presentations/MozFest2013/data/')\n",
      "\n",
      "nyt = open('../data/nyt_title_data.csv') # check the structure of this file!\n",
      "nyt_data = []\n",
      "nyt_labels = []\n",
      "csv_reader = csv.reader(nyt)\n",
      "\n",
      "for line in csv_reader:\n",
      "    nyt_labels.append(int(line[0]))\n",
      "    nyt_data.append(line[1])\n",
      "\n",
      "nyt.close()\n",
      "\n",
      "trainset_size = int(round(len(nyt_data)*0.75)) # i chose this threshold arbitrarily...to discuss\n",
      "print 'The training set size for this classifier is ' + str(trainset_size) + '\\n'\n",
      "\n",
      "X_train = np.array([''.join(el) for el in nyt_data[0:trainset_size]])\n",
      "y_train = np.array([el for el in nyt_labels[0:trainset_size]])\n",
      "\n",
      "X_test = np.array([''.join(el) for el in nyt_data[trainset_size+1:len(nyt_data)]])   \n",
      "y_test = np.array([el for el in nyt_labels[trainset_size+1:len(nyt_labels)]])  \n",
      "\n",
      "#print(X_train)\n",
      "\n",
      "vectorizer = TfidfVectorizer(min_df=2, \n",
      "    ngram_range=(1, 2), \n",
      "    stop_words='english', \n",
      "    strip_accents='unicode', \n",
      "    norm='l2')\n",
      "                             \n",
      "test_string = unicode(nyt_data[0])\n",
      "\n",
      "print \"Example string: \" + test_string\n",
      "print \"Preprocessed string: \" + vectorizer.build_preprocessor()(test_string)\n",
      "print \"Tokenized string:\" + str(vectorizer.build_tokenizer()(test_string))\n",
      "print \"N-gram data string:\" + str(vectorizer.build_analyzer()(test_string))\n",
      "print \"\\n\"\n",
      "    \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The training set size for this classifier is 1621\n",
        "\n",
        "Example string: Police to Seize Cars Of People Accused Of Drunken Driving\n",
        "Preprocessed string: police to seize cars of people accused of drunken driving\n",
        "Tokenized string:[u'Police', u'to', u'Seize', u'Cars', u'Of', u'People', u'Accused', u'Of', u'Drunken', u'Driving']\n",
        "N-gram data string:[u'police', u'seize', u'cars', u'people', u'accused', u'drunken', u'driving', u'police seize', u'seize cars', u'cars people', u'people accused', u'accused drunken', u'drunken driving']\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = vectorizer.fit_transform(X_train)\n",
      "X_test = vectorizer.transform(X_test)\n",
      "\n",
      "nb_classifier = MultinomialNB().fit(X_train, y_train)\n",
      "\n",
      "y_nb_predicted = nb_classifier.predict(X_test)\n",
      "\n",
      "print \"MODEL: Multinomial Naive Bayes\\n\"\n",
      "\n",
      "print 'The precision for this classifier is ' + str(metrics.precision_score(y_test, y_nb_predicted))\n",
      "print 'The recall for this classifier is ' + str(metrics.recall_score(y_test, y_nb_predicted))\n",
      "print 'The f1 for this classifier is ' + str(metrics.f1_score(y_test, y_nb_predicted))\n",
      "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(y_test, y_nb_predicted))\n",
      "\n",
      "print '\\nHere is the classification report:'\n",
      "print classification_report(y_test, y_nb_predicted)\n",
      "\n",
      "#simple thing to do would be to up the n-grams to bigrams; try varying ngram_range from (1, 1) to (1, 2)\n",
      "#we could also modify the vectorizer to stem or lemmatize\n",
      "print '\\nHere is the confusion matrix:'\n",
      "print metrics.confusion_matrix(y_test, y_nb_predicted, labels=unique(nyt_labels))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MODEL: Multinomial Naive Bayes\n",
        "\n",
        "The precision for this classifier is 0.691841627658\n",
        "The recall for this classifier is 0.571428571429\n",
        "The f1 for this classifier is 0.524504123039\n",
        "The accuracy for this classifier is 0.571428571429\n",
        "\n",
        "Here is the classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          3       0.90      0.19      0.31        48\n",
        "         12       1.00      0.06      0.11        34\n",
        "         15       0.83      0.12      0.21        41\n",
        "         16       0.64      0.55      0.59       111\n",
        "         19       0.47      0.90      0.62       172\n",
        "         20       0.75      0.72      0.74        97\n",
        "         29       1.00      0.19      0.33        36\n",
        "\n",
        "avg / total       0.69      0.57      0.52       539\n",
        "\n",
        "\n",
        "Here is the confusion matrix:\n",
        "[[  9   0   0   7  25   7   0]\n",
        " [  0   2   0   3  26   3   0]\n",
        " [  1   0   5   4  27   4   0]\n",
        " [  0   0   0  61  45   5   0]\n",
        " [  0   0   0  16 154   2   0]\n",
        " [  0   0   1   3  23  70   0]\n",
        " [  0   0   0   1  26   2   7]]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#What are the top N most predictive features per class?\n",
      "N = 10\n",
      "vocabulary = np.array([t for t, i in sorted(vectorizer.vocabulary_.iteritems(), key=itemgetter(1))])\n",
      "\n",
      "for i, label in enumerate(nyt_labels):\n",
      "    if i == 7: # hack...\n",
      "        break\n",
      "    topN = np.argsort(nb_classifier.coef_[i])[-N:]\n",
      "    print \"\\nThe top %d most informative features for topic code %s: \\n%s\" % (N, label, \" \".join(vocabulary[topN]))\n",
      "    #print topN"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "The top 10 most informative features for topic code 3: \n",
        "tobacco costs drugs cancer doctors medicare health care new drug\n",
        "\n",
        "The top 10 most informative features for topic code 19: \n",
        "murder york new york gun officer suspect new police crime case\n",
        "\n",
        "The top 10 most informative features for topic code 15: \n",
        "big new market stocks pay wall chief enron deal microsoft\n",
        "\n",
        "The top 10 most informative features for topic code 16: \n",
        "military overview baghdad 11 challenged nation challenged bush nation war iraq\n",
        "\n",
        "The top 10 most informative features for topic code 20: \n",
        "overview russian india crisis arafat japan leader new israel china\n",
        "\n",
        "The top 10 most informative features for topic code 3: \n",
        "senate testing president 2000 campaign 2000 politics clinton bush democrats president campaign\n",
        "\n",
        "The top 10 most informative features for topic code 15: \n",
        "win tennis bowl playoffs world series world yankees game series baseball\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import LinearSVC\n",
      "\n",
      "svm_classifier = LinearSVC().fit(X_train, y_train)\n",
      "\n",
      "y_svm_predicted = svm_classifier.predict(X_test)\n",
      "print \"MODEL: Linear SVC\\n\"\n",
      "\n",
      "print 'The precision for this classifier is ' + str(metrics.precision_score(y_test, y_svm_predicted))\n",
      "print 'The recall for this classifier is ' + str(metrics.recall_score(y_test, y_svm_predicted))\n",
      "print 'The f1 for this classifier is ' + str(metrics.f1_score(y_test, y_svm_predicted))\n",
      "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(y_test, y_svm_predicted))\n",
      "\n",
      "print '\\nHere is the classification report:'\n",
      "print classification_report(y_test, y_svm_predicted)\n",
      "\n",
      "#simple thing to do would be to up the n-grams to bigrams; try varying ngram_range from (1, 1) to (1, 2)\n",
      "#we could also modify the vectorizer to stem or lemmatize\n",
      "print '\\nHere is the confusion matrix:'\n",
      "print metrics.confusion_matrix(y_test, y_svm_predicted, labels=unique(nyt_labels))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MODEL: Linear SVC\n",
        "\n",
        "The precision for this classifier is 0.653750401665\n",
        "The recall for this classifier is 0.649350649351\n",
        "The f1 for this classifier is 0.64384871703\n",
        "The accuracy for this classifier is 0.649350649351\n",
        "\n",
        "Here is the classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          3       0.80      0.50      0.62        48\n",
        "         12       0.44      0.44      0.44        34\n",
        "         15       0.41      0.32      0.36        41\n",
        "         16       0.73      0.62      0.67       111\n",
        "         19       0.63      0.78      0.70       172\n",
        "         20       0.70      0.76      0.73        97\n",
        "         29       0.69      0.56      0.62        36\n",
        "\n",
        "avg / total       0.65      0.65      0.64       539\n",
        "\n",
        "\n",
        "Here is the confusion matrix:\n",
        "[[ 24   1   4   1   9   9   0]\n",
        " [  2  15   2   1   8   3   3]\n",
        " [  2   6  13   1  12   6   1]\n",
        " [  1   5   3  69  27   6   0]\n",
        " [  1   5   4  18 135   6   3]\n",
        " [  0   2   2   4  13  74   2]\n",
        " [  0   0   4   1  10   1  20]]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#What are the top N most predictive features per class?\n",
      "N = 10\n",
      "vocabulary = np.array([t for t, i in sorted(vectorizer.vocabulary_.iteritems(), key=itemgetter(1))])\n",
      "\n",
      "for i, label in enumerate(nyt_labels):\n",
      "    if i == 7: # hack...\n",
      "        break\n",
      "    topN = np.argsort(svm_classifier.coef_[i])[-N:]\n",
      "    print \"\\nThe top %d most informative features for topic code %s: \\n%s\" % (N, label, \" \".join(vocabulary[topN]))\n",
      "    #print topN"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "The top 10 most informative features for topic code 3: \n",
        "driving care scientists cancer fat doctors health drug tobacco medicare\n",
        "\n",
        "The top 10 most informative features for topic code 19: \n",
        "fallen prison narcotics diallo police officer guns robbery gun crime\n",
        "\n",
        "The top 10 most informative features for topic code 15: \n",
        "firms morgan workers corporations pricing market deal stocks microsoft enron\n",
        "\n",
        "The top 10 most informative features for topic code 16: \n",
        "generals abuse hussein detainees rumsfeld troops missile nato 11 iraq\n",
        "\n",
        "The top 10 most informative features for topic code 20: \n",
        "pakistan china milosevic europe chinese india japan mideast israel russian\n",
        "\n",
        "The top 10 most informative features for topic code 3: \n",
        "impeachment whitewater ethics gingrich census president clinton politics democrats campaign\n",
        "\n",
        "The top 10 most informative features for topic code 15: \n",
        "best tennis bowl knicks yankees match game coach baseball series\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "maxent_classifier = LogisticRegression().fit(X_train, y_train)\n",
      "\n",
      "y_maxent_predicted = maxent_classifier.predict(X_test)\n",
      "print \"MODEL: Maximum Entropy\\n\"\n",
      "\n",
      "print 'The precision for this classifier is ' + str(metrics.precision_score(y_test, y_maxent_predicted))\n",
      "print 'The recall for this classifier is ' + str(metrics.recall_score(y_test, y_maxent_predicted))\n",
      "print 'The f1 for this classifier is ' + str(metrics.f1_score(y_test, y_maxent_predicted))\n",
      "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(y_test, y_maxent_predicted))\n",
      "\n",
      "print '\\nHere is the classification report:'\n",
      "print classification_report(y_test, y_maxent_predicted)\n",
      "\n",
      "#simple thing to do would be to up the n-grams to bigrams; try varying ngram_range from (1, 1) to (1, 2)\n",
      "#we could also modify the vectorizer to stem or lemmatize\n",
      "print '\\nHere is the confusion matrix:'\n",
      "print metrics.confusion_matrix(y_test, y_maxent_predicted, labels=unique(nyt_labels))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MODEL: Maximum Entropy\n",
        "\n",
        "The precision for this classifier is 0.654841081319\n",
        "The recall for this classifier is 0.584415584416\n",
        "The f1 for this classifier is 0.549282524728\n",
        "The accuracy for this classifier is 0.584415584416\n",
        "\n",
        "Here is the classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          3       0.85      0.23      0.36        48\n",
        "         12       0.57      0.12      0.20        34\n",
        "         15       0.73      0.20      0.31        41\n",
        "         16       0.67      0.56      0.61       111\n",
        "         19       0.49      0.89      0.63       172\n",
        "         20       0.75      0.71      0.73        97\n",
        "         29       0.89      0.22      0.36        36\n",
        "\n",
        "avg / total       0.65      0.58      0.55       539\n",
        "\n",
        "\n",
        "Here is the confusion matrix:\n",
        "[[ 11   0   1   3  26   7   0]\n",
        " [  1   4   0   4  22   3   0]\n",
        " [  1   2   8   1  25   4   0]\n",
        " [  0   0   0  62  43   6   0]\n",
        " [  0   0   0  17 153   2   0]\n",
        " [  0   1   2   4  20  69   1]\n",
        " [  0   0   0   1  26   1   8]]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#What are the top N most predictive features per class?\n",
      "N = 10\n",
      "vocabulary = np.array([t for t, i in sorted(vectorizer.vocabulary_.iteritems(), key=itemgetter(1))])\n",
      "\n",
      "for i, label in enumerate(nyt_labels):\n",
      "    if i == 7: # hack...\n",
      "        break\n",
      "    topN = np.argsort(maxent_classifier.coef_[i])[-N:]\n",
      "    print \"\\nThe top %d most informative features for topic code %s: \\n%s\" % (N, label, \" \".join(vocabulary[topN]))\n",
      "    #print topN"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "The top 10 most informative features for topic code 3: \n",
        "hospitals scientists drugs tobacco cancer doctors medicare health care drug\n",
        "\n",
        "The top 10 most informative features for topic code 19: \n",
        "officers prison murder robbery suspect officer gun case police crime\n",
        "\n",
        "The top 10 most informative features for topic code 15: \n",
        "big investors pay wall market chief stocks deal enron microsoft\n",
        "\n",
        "The top 10 most informative features for topic code 16: \n",
        "missile challenged troops afghanistan nation challenged nato nation war 11 iraq\n",
        "\n",
        "The top 10 most informative features for topic code 20: \n",
        "chinese israelis arafat leader mideast india japan china russian israel\n",
        "\n",
        "The top 10 most informative features for topic code 3: \n",
        "testing president 2000 race senate bush politics clinton president democrats campaign\n",
        "\n",
        "The top 10 most informative features for topic code 15: \n",
        "best match knicks playoffs tennis bowl yankees game series baseball\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Unsupervised learning: Topic modeling in Python\n",
      "\n",
      "Now we're going to go over some typical topic modeling by using the popular [Gensim](http://radimrehurek.com/gensim/) library.\n",
      "\n",
      "The nice thing about Gensim is that it's ready to be applied to large datasets as it incorporates both the online version of LDA and distributed computing capability.\n",
      "\n",
      "We won't go over those features in this tutorial, since that would take hours to show a single example, and the NYTimes dataset is really quite small and can be run on a single machine."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim import corpora, models, similarities\n",
      "from itertools import chain\n",
      "import nltk\n",
      "from nltk.corpus import stopwords\n",
      "from operator import itemgetter\n",
      "import re\n",
      "\n",
      "url_pattern = r'https?:\\/\\/(.*[\\r\\n]*)+'\n",
      "\n",
      "documents = [nltk.clean_html(document) for document in nyt_data]\n",
      "stoplist = stopwords.words('english')\n",
      "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
      "          for document in documents]\n",
      "\n",
      "dictionary = corpora.Dictionary(texts)\n",
      "corpus = [dictionary.doc2bow(text) for text in texts]\n",
      "\n",
      "tfidf = models.TfidfModel(corpus) \n",
      "corpus_tfidf = tfidf[corpus]\n",
      "\n",
      "#lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=100)\n",
      "#lsi.print_topics(20)\n",
      "\n",
      "n_topics = 60\n",
      "lda = models.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=n_topics)\n",
      "\n",
      "for i in range(0, n_topics):\n",
      "    temp = lda.show_topic(i, 10)\n",
      "    terms = []\n",
      "    for term in temp:\n",
      "        terms.append(term[1])\n",
      "    print \"Top 10 terms for topic #\" + str(i) + \": \"+ \", \".join(terms)\n",
      "    \n",
      "print \n",
      "print 'Which LDA topic maximally describes a document?\\n'\n",
      "print 'Original document: ' + documents[1]\n",
      "print 'Preprocessed document: ' + str(texts[1])\n",
      "print 'Matrix Market format: ' + str(corpus[1])\n",
      "print 'Topic probability mixture: ' + str(lda[corpus[1]])\n",
      "print 'Maximally probable topic: topic #' + str(max(lda[corpus[1]],key=itemgetter(1))[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top 10 terms for topic #0: cites, force, falluja, not,, memories, troops, man, vote, attack, beach\n",
        "Top 10 terms for topic #1: mind, drive?, abducts, legend, jolted, another, 40, microsoft, judge, path\n",
        "Top 10 terms for topic #2: born, setting, rally, pullout, diplomacy, homes, split, baghdad, press, allies\n",
        "Top 10 terms for topic #3: iraqi, blasts, next, capital;, war:, all-around, volunteer;, strain, unburied, viacom\n",
        "Top 10 terms for topic #4: york, crack, mccain,, ballot, disneyland, poll,, gangland, innocent, new, nazis\n",
        "Top 10 terms for topic #5: lawmakers, tone, disaster, recruiting, mets, rebel, still, gunfire, city, end\n",
        "Top 10 terms for topic #6: uses, iraq, strife, unforeseen,, algeria, sledgehammer, eases, chechnya, sarajevo, hints\n",
        "Top 10 terms for topic #7: fire, drafting, deeply, divides, strip, orders, charter, german, weakens, vs.\n",
        "Top 10 terms for topic #8: china's, flows, clans, unruly, gaza,, compete, challenged, brain, void, cash\n",
        "Top 10 terms for topic #9: ban, china, doctors', violation, angola, diamond, concerns, arms, key, cited\n",
        "Top 10 terms for topic #10: wins, israel, repay, jordanian, assist, meeting, saved, iraq,, millions, puts\n",
        "Top 10 terms for topic #11: fled, steps, feeling, rules, economy, see, leaders, court, war, effort,\n",
        "Top 10 terms for topic #12: fire:, president, defeats, irish, secret, parents, companies, meeting, court, 2\n",
        "Top 10 terms for topic #13: plans, weakened, shift,, swing, mixed, region, afghan, manifesto, communists, new,\n",
        "Top 10 terms for topic #14: entrepreneurs,, ambitious, long,, announces, f.b.i.,, nation, europe, face, marines, little\n",
        "Top 10 terms for topic #15: threats, decisions, bush,, behind, hispanics, makes, h.m.o., white, back, big\n",
        "Top 10 terms for topic #16: kabul, researchers, came, chaos, western, opens, reprimands, punishes, stop, abuse\n",
        "Top 10 terms for topic #17: 20, months, changes, time, times, aids, public, oil, violence, friends\n",
        "Top 10 terms for topic #18: f.d.a., insurance, tobacco, debate, 4, many, egypt, surprised, town, keep\n",
        "Top 10 terms for topic #19: criminal, eve, takes, help,, measures, report:, embattled, eavesdropping, cost, seek\n",
        "Top 10 terms for topic #20: investigation;, peru:, outlook;, rescue, reviewing, dean, arrests, cleric, path, hopes\n",
        "Top 10 terms for topic #21: opinion, bold, becomes, looking, shape, liability, counts, surprised, bombing, oath\n",
        "Top 10 terms for topic #22: star, tax, palestinians, aid, linked, russia's, victims, firm, ills, computer\n",
        "Top 10 terms for topic #23: political, straight, detainee, yankees, woods, masters, 4th, shift, spans, spectrum\n",
        "Top 10 terms for topic #24: shake-up, russia:, opener, hold, he'll, security;, yeltsin, overview;, takes, shaky,\n",
        "Top 10 terms for topic #25: defense, cite, confirms, promote, seat, yanks, fighting, office, remains, enron\n",
        "Top 10 terms for topic #26: premier, advance, races, system, health, way, deaths, serbs', assassinated;, appear\n",
        "Top 10 terms for topic #27: wall, halt, named, turn, weakens, end, left, starts, stalling, bills,\n",
        "Top 10 terms for topic #28: defines, appears, phase, diversity, tolerance, net,, accuse, return, tough, held\n",
        "Top 10 terms for topic #29: revel, ex-settlements, gazans, sift, contest, candidates, spin, unbundling, tribunal, challenge\n",
        "Top 10 terms for topic #30: rebuilding, share, u.s., terekhovo, iraqis, bush, purchasing, journal;, acquisition, old\n",
        "Top 10 terms for topic #31: officially,, 'borat', fun, iron, one-child, policy,, rethinks, signal, buchanan, pessimistic\n",
        "Top 10 terms for topic #32: international, business;, revives, away, devils, cup, drop, passes, resistance, expand\n",
        "Top 10 terms for topic #33: 2000, campaign:, primary, government, penalty, led, hun, ruler, cambodia's, enjoying\n",
        "Top 10 terms for topic #34: wealth, claims, later,, al, qaeda, let, convicted, recount, sudan?, overview;\n",
        "Top 10 terms for topic #35: hijackers, seeks, disputes, block, demand, village, blair, deaths, measure, g.o.p\n",
        "Top 10 terms for topic #36: power, serbs, fatigue, sought, winning, u.s.,, open, 9/11, war, future\n",
        "Top 10 terms for topic #37: green, angry, boom, '05?, activity, designs, street's, berets;, berets, 12\n",
        "Top 10 terms for topic #38: plaintiff, visitors, audit, tighter, fragmented, veto, finds, security, campaigns, microsoft:\n",
        "Top 10 terms for topic #39: british, weapons, bombing, bases, term, risks, tour, finance, militia, '96\n",
        "Top 10 terms for topic #40: history, counsel's, weigh, turkey, flouts, backdoor,, boy, sanctions, fall, serbs\n",
        "Top 10 terms for topic #41: aide, 9, polls, raising, said, chirac, state, break, top, provisional\n",
        "Top 10 terms for topic #42: search, president's, hunt, gene, years,, moved, operations;, undermine, covert, africa\n",
        "Top 10 terms for topic #43: creating, speaker, year's, down:, career;, arlington, 'unknowns', science:, yields, pakistanis\n",
        "Top 10 terms for topic #44: carry, iraq's, disclosed, lung, kosovo, ready, assessment, delay, aides, war,\n",
        "Top 10 terms for topic #45: construction, racketeering, king, tied, leave, city, collected, jordanian, house, white\n",
        "Top 10 terms for topic #46: sale, skates, investment,, u.s., asian, seekers, overseer, fierce, family, islamic\n",
        "Top 10 terms for topic #47: desperate, yields, limits, rebels, tied,, rue, hands, law, judges, police\n",
        "Top 10 terms for topic #48: set, house, rule, ethics, stump, retreat,, pain, rise, campaign, war\n",
        "Top 10 terms for topic #49: aids, go, defector, reforms, families, road, 39, rocky, invited, biological"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Top 10 terms for topic #50: win, soviet, final, gear, status, insiders', board, spy, biological, warns\n",
        "Top 10 terms for topic #51: likely, stanley, authority, troops;, 7, try, cleric, limit, view, 11\n",
        "Top 10 terms for topic #52: urged, raise, investors, faith, flow, mexico, states, clinton, wear, sleeve\n",
        "Top 10 terms for topic #53: africa:, rift, overview;, message, mideast, aide, set, bares, dissenting, frenzy\n",
        "Top 10 terms for topic #54: one, president:, testing, overview;, lobbyist,, tribunals, playoffs;, alter, giants, panel\n",
        "Top 10 terms for topic #55: balance, hours;, four, president:, testing, others, details, democrats, stalling, bills,\n",
        "Top 10 terms for topic #56: backs, military, killing, liberia, cabinet, hit, serb, israel, bosnia, battle:\n",
        "Top 10 terms for topic #57: senate, links, republican, fellow, mississippian, vulnerable, appear, lott, agency, sell\n",
        "Top 10 terms for topic #58: pro, basketball;, clinton, leak, camp, nato, plotters', laden, bin, eavesdropping\n",
        "Top 10 terms for topic #59: sets, yeltsin, wish, wonderful, traveling, olympic, relief, time,, secrets, efforts\n",
        "\n",
        "Which LDA topic maximally describes a document?\n",
        "\n",
        "Original document: Complex Web Of Madrid Plot Still Entangled\n",
        "Preprocessed document: ['complex', 'web', 'madrid', 'plot', 'still', 'entangled']\n",
        "Matrix Market format: [(7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)]\n",
        "Topic probability mixture: [(3, 0.57407952695455311), (5, 0.14517024123385933), (39, 0.1450359460973023)]\n",
        "Maximally probable topic: topic #3\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Big picture questions:\n",
      "\n",
      "1.  How do the different supervised models compare against each other?  \n",
      "    1. What's the tradeoffs between the metrics per model?\n",
      "    2. What about per class?  Are some models better than others are certain classes?\n",
      "    3. What if we had had more data?  Would some models get better than others?\n",
      "    5. What if our *observations* had more data?  Instead of titles, we used lead paragraphs or even the full document?\n",
      "    6. What if our feature space was different?  Instead of unigrams or bigrams, we used trigrams?  Parts-of-speech?\n",
      "    4. Is there something about the **underlying language** structure that leads certain models to being better than others?\n",
      "2.  How do the supervised models compare against the unsupervised model?\n",
      "    1. Are they \"better?\"  If so, how?\n",
      "    2. What did we need to train a supervised model?  What did we need to train an unsupervised model?\n",
      "    3. On that note, when is it more appropriate to use an unsupervised model over a supervised model?\n",
      "    4. How do you choose *k* number of topics for an unsupervised model?\n",
      "    5. What happens if you run the unsupervised model again?  What about the supervised model?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}